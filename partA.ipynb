{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# DA6401 Assignment 2 - Part A\n## Training CNN from Scratch on iNaturalist Dataset","metadata":{}},{"cell_type":"code","source":"!curl https://storage.googleapis.com/wandb_datasets/nature_12K.zip --output nature_12K.zip\n!unzip nature_12K.zip > /dev/null 2>&1\n!rm nature_12K.zip","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T18:51:44.768218Z","iopub.execute_input":"2025-04-18T18:51:44.768497Z","iopub.status.idle":"2025-04-18T18:52:33.338212Z","shell.execute_reply.started":"2025-04-18T18:51:44.768478Z","shell.execute_reply":"2025-04-18T18:52:33.337142Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!python -m pip install lightning","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T18:52:33.339798Z","iopub.execute_input":"2025-04-18T18:52:33.340204Z","iopub.status.idle":"2025-04-18T18:54:05.376606Z","shell.execute_reply.started":"2025-04-18T18:52:33.340178Z","shell.execute_reply":"2025-04-18T18:54:05.375780Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install wandb\n\nimport wandb\nwandb.login(key='130161b8988911058327a18dbbdfb663c58411b2')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T18:54:05.377668Z","iopub.execute_input":"2025-04-18T18:54:05.377977Z","iopub.status.idle":"2025-04-18T18:54:16.837535Z","shell.execute_reply.started":"2025-04-18T18:54:05.377952Z","shell.execute_reply":"2025-04-18T18:54:16.836769Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Import necessary libraries\nimport os\nimport math\nimport torch\nimport lightning as L\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader, Subset\nfrom torchvision.datasets import ImageFolder\nfrom torchmetrics import Accuracy\nfrom lightning.pytorch.loggers import WandbLogger\nfrom lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint\nimport wandb\nimport numpy as np\nimport matplotlib.pyplot as plt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T18:54:16.839308Z","iopub.execute_input":"2025-04-18T18:54:16.839701Z","iopub.status.idle":"2025-04-18T18:54:28.269997Z","shell.execute_reply.started":"2025-04-18T18:54:16.839682Z","shell.execute_reply":"2025-04-18T18:54:28.269406Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":" ###  Building a Flexible CNN Model","metadata":{}},{"cell_type":"code","source":"class NatureCNN(L.LightningModule):\n    def __init__(self,\n                 base_filters=32,\n                 filter_strategy='double',\n                 base_kernel=3,\n                 kernel_strategy='same',\n                 batch_norm=True,\n                 conv_activation='relu',\n                 dense_activation='relu',\n                 dense_size=128,\n                 learning_rate=1e-3,\n                 weight_decay=1e-4,\n                 dropout=0.2):\n        \"\"\"\n        Flexible CNN model for iNaturalist dataset classification.\n        \n        Args:\n            base_filters: Starting number of filters in first convolutional layer\n            filter_strategy: Strategy for scaling filters across layers ['same', 'double', 'halve', 'alternate']\n            base_kernel: Base kernel size for convolutional layers\n            kernel_strategy: Strategy for kernel sizes ['same', 'decrease', 'alternate', 'pyramid']\n            batch_norm: Whether to use batch normalization\n            conv_activation: Activation function for convolutional layers\n            dense_activation: Activation function for dense layers\n            dense_size: Number of neurons in dense layer\n            learning_rate: Learning rate for optimizer\n            weight_decay: Weight decay for regularization\n            dropout: Dropout rate\n        \"\"\"\n        super().__init__()\n        self.save_hyperparameters()\n\n        # Generate architecture configuration\n        self.filters = self.get_filter_strategy(base_filters, filter_strategy)\n        self.kernel_sizes = self.generate_kernel_sizes(base_kernel, kernel_strategy)\n        \n        # Validate configuration\n        if len(self.filters) != len(self.kernel_sizes):\n            raise ValueError(\"Filter numbers and kernel sizes must match\")\n\n        # Build convolutional blocks\n        self.features = nn.Sequential()\n        in_channels = 3\n        \n        for i, (out_channels, k_size) in enumerate(zip(self.filters, self.kernel_sizes)):\n            # Ensure odd kernel size for symmetric padding\n            k_size = k_size if k_size % 2 else k_size + 1\n            padding = k_size // 2\n            \n            # Add logging for model construction\n            print(f\"Layer {i+1}: {in_channels} -> {out_channels}, kernel: {k_size}x{k_size}\")\n            \n            self.features.append(nn.Conv2d(in_channels, out_channels, k_size, padding=padding))\n            \n            if self.hparams.batch_norm:\n                self.features.append(nn.BatchNorm2d(out_channels))\n            \n            self.features.append(self._get_activation(self.hparams.conv_activation))\n            self.features.append(nn.MaxPool2d(2, 2))\n            in_channels = out_channels\n\n        # Calculate classifier input size\n        with torch.no_grad():\n            dummy = torch.zeros(1, 3, 128, 128)\n            self.feature_size = self.features(dummy).flatten(1).size(1)\n\n        # Build classifier\n        self.classifier = nn.Sequential(\n            nn.Linear(self.feature_size, dense_size),\n            self._get_activation(self.hparams.dense_activation),\n            nn.Dropout(dropout),\n            nn.Linear(dense_size, 10)  # 10 classes in the iNaturalist subset\n        )\n\n        # Metrics\n        self.train_acc = Accuracy(task='multiclass', num_classes=10)\n        self.val_acc = Accuracy(task='multiclass', num_classes=10)\n        self.test_acc = Accuracy(task='multiclass', num_classes=10)\n\n    @staticmethod\n    def get_filter_strategy(base: int, strategy: str, num_layers=5) -> list:\n        \"\"\"Generate filter numbers based on base and strategy\"\"\"\n        strategies = {\n            'same': [base] * num_layers,\n            'double': [base * (2**i) for i in range(num_layers)],\n            'halve': [max(8, base // (2**i)) for i in range(num_layers)],\n            'alternate': [base * (2 if i%2 else 1) for i in range(num_layers)]\n        }\n        return strategies[strategy.lower()]\n\n    @staticmethod\n    def generate_kernel_sizes(base: int, strategy: str, num_layers=5) -> list:\n        \"\"\"Generate kernel sizes based on base and strategy\"\"\"\n        strategies = {\n            'same': [base] * num_layers,\n            'decrease': [max(3, base - 2*i) for i in range(num_layers)],\n            'alternate': [base if i%2 else (base-2) for i in range(num_layers)],\n            'pyramid': [base + 2*i for i in range(num_layers//2)] + \n                       [base + 2*(num_layers//2 - i) for i in range(1, num_layers-num_layers//2+1)]\n        }\n        return strategies[strategy.lower()]\n\n    def _get_activation(self, name: str) -> nn.Module:\n        \"\"\"Map activation name to PyTorch module\"\"\"\n        activations = {\n            'relu': nn.ReLU(),\n            'gelu': nn.GELU(),\n            'silu': nn.SiLU(),\n            'mish': nn.Mish(),\n            'leaky_relu': nn.LeakyReLU(0.1),\n            'elu': nn.ELU(),\n            'selu': nn.SELU(),\n            'tanh': nn.Tanh(),\n            'sigmoid': nn.Sigmoid()\n        }\n        return activations[name.lower()]\n\n    def forward(self, x):\n        x = self.features(x)\n        x = x.flatten(1)\n        return self.classifier(x)\n\n    def training_step(self, batch, batch_idx):\n        x, y = batch\n        logits = self(x)\n        loss = F.cross_entropy(logits, y)\n        self.log('train_loss', loss, prog_bar=True , on_step=False, on_epoch=True)\n        self.train_acc(logits, y)\n        self.log('train_acc', self.train_acc, prog_bar=True, on_step=False, on_epoch=True)\n        return loss\n\n    def validation_step(self, batch, batch_idx):\n        x, y = batch\n        logits = self(x)\n        loss = F.cross_entropy(logits, y)\n        self.log('val_loss', loss, prog_bar=True, on_step=False, on_epoch=True)\n        self.val_acc(logits, y)\n        self.log('val_acc', self.val_acc, prog_bar=True, on_step=False, on_epoch=True)\n\n    def test_step(self, batch, batch_idx):\n        x, y = batch\n        logits = self(x)\n        loss = F.cross_entropy(logits, y)\n        self.log('test_loss', loss)\n        self.test_acc(logits, y)\n        self.log('test_acc', self.test_acc, prog_bar=True, on_step=False, on_epoch=True)\n        \n\n    def configure_optimizers(self):\n        optimizer = torch.optim.AdamW(\n            self.parameters(),\n            lr=self.hparams.learning_rate,\n            weight_decay=self.hparams.weight_decay\n        )\n        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n            optimizer,\n            mode='max',\n            factor=0.5,\n            patience=2\n        )\n        return {\n            'optimizer': optimizer,\n            'lr_scheduler': {\n                'scheduler': scheduler,\n                'monitor': 'val_acc',\n                'interval': 'epoch',\n                'frequency': 1\n            }\n        }\n        \n    def calculate_computations(self, image_size=128):\n        \"\"\"\n        Calculate the total number of computations (FLOPs) performed by the network\n        \n        Args:\n            image_size: Size of input image (assumed square)\n            \n        Returns:\n            Total number of multiplication and addition operations\n        \"\"\"\n        total_flops = 0\n        input_size = image_size\n        \n        # Compute FLOPs for each convolutional layer\n        in_channels = 3\n        for i, (out_channels, k_size) in enumerate(zip(self.filters, self.kernel_sizes)):\n            # Each output pixel requires k*k*in_channels multiplications and additions\n            # Number of output pixels = input_size^2 (due to padding)\n            # Number of output channels = out_channels\n            flops_per_layer = input_size**2 * out_channels * k_size**2 * in_channels\n            \n            # Add batch norm operations if used (4 operations per element)\n            if self.hparams.batch_norm:\n                flops_per_layer += 4 * input_size**2 * out_channels\n            \n            # Add activation function operations (1 operation per element)\n            flops_per_layer += input_size**2 * out_channels\n            \n            print(f\"Layer {i+1}: {flops_per_layer} FLOPs\")\n            total_flops += flops_per_layer\n            \n            # Update for next layer (maxpool reduces spatial dimensions by half)\n            input_size = input_size // 2\n            in_channels = out_channels\n        \n        # Compute FLOPs for the dense layer\n        flops_dense = self.feature_size * self.hparams.dense_size\n        # Add activation\n        flops_dense += self.hparams.dense_size\n        # Add dropout (1 operation per element)\n        flops_dense += self.hparams.dense_size\n        \n        print(f\"Dense layer: {flops_dense} FLOPs\")\n        total_flops += flops_dense\n        \n        # Compute FLOPs for the output layer\n        flops_output = self.hparams.dense_size * 10\n        print(f\"Output layer: {flops_output} FLOPs\")\n        total_flops += flops_output\n        \n        return total_flops\n    \n    def count_parameters(self):\n        \"\"\"\n        Calculate the total number of trainable parameters in the network\n        \n        Returns:\n            Total number of parameters\n        \"\"\"\n        total_params = 0\n        in_channels = 3\n        \n        # Count parameters for convolutional layers\n        for i, (out_channels, k_size) in enumerate(zip(self.filters, self.kernel_sizes)):\n            # Conv weights: out_channels * in_channels * k_size * k_size\n            params_conv = out_channels * in_channels * k_size**2\n            # Conv bias: out_channels\n            params_conv += out_channels\n            \n            # BatchNorm parameters: 2 * out_channels (gamma and beta)\n            params_bn = 2 * out_channels if self.hparams.batch_norm else 0\n            \n            layer_params = params_conv + params_bn\n            print(f\"Layer {i+1}: {layer_params} parameters\")\n            total_params += layer_params\n            \n            in_channels = out_channels\n        \n        # Count parameters for dense layer\n        params_dense = self.feature_size * self.hparams.dense_size + self.hparams.dense_size\n        print(f\"Dense layer: {params_dense} parameters\")\n        total_params += params_dense\n        \n        # Count parameters for output layer\n        params_output = self.hparams.dense_size * 10 + 10\n        print(f\"Output layer: {params_output} parameters\")\n        total_params += params_output\n        \n        return total_params\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T19:12:39.407459Z","iopub.execute_input":"2025-04-18T19:12:39.408365Z","iopub.status.idle":"2025-04-18T19:12:39.433472Z","shell.execute_reply.started":"2025-04-18T19:12:39.408333Z","shell.execute_reply":"2025-04-18T19:12:39.432677Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Calculation of Computations and Parameters for Question 1","metadata":{}},{"cell_type":"code","source":"# Create a model with default parameters to calculate computations and parameters\ndefault_model = NatureCNN()\n\n# Print the model architecture\nprint(\"\\nModel Architecture:\")\nprint(default_model)\n\n# Calculate and print total computations\nprint(\"\\nTotal Computations (FLOPs):\")\ntotal_flops = default_model.calculate_computations()\nprint(f\"Total FLOPs: {total_flops:,}\")\n\n# Calculate and print total parameters\nprint(\"\\nTotal Parameters:\")\ntotal_params = default_model.count_parameters()\nprint(f\"Total Parameters: {total_params:,}\")\n\n# Analytical calculation for arbitrary values\nprint(\"\\nAnalytical calculations for generic model:\")\nprint(\"For a model with m filters in each layer of size k×k and n neurons in dense layer\")\nprint(\"Total computations (FLOPs) = 5*(image_size^2 * m * k^2 * m) + feature_size*n + n*10\")\nprint(\"Total parameters = 5*(m * m * k^2 + m) + feature_size*n + n + n*10 + 10\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T19:12:43.256492Z","iopub.execute_input":"2025-04-18T19:12:43.257053Z","iopub.status.idle":"2025-04-18T19:12:43.316027Z","shell.execute_reply.started":"2025-04-18T19:12:43.257027Z","shell.execute_reply":"2025-04-18T19:12:43.315351Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Training the Model and Hyperparameter Tuning","metadata":{}},{"cell_type":"code","source":"class NatureDataModule(L.LightningDataModule):\n    def __init__(self, data_dir='/kaggle/working/inaturalist_12K/', image_size=128, \n                 batch_size=32, num_workers=4, data_aug=True):\n        \"\"\"\n        Data module for the iNaturalist dataset with stratified train/validation split\n        \n        Args:\n            data_dir: Directory containing the dataset\n            image_size: Size to resize images to\n            batch_size: Batch size for training\n            num_workers: Number of workers for data loading\n            data_aug: Whether to apply data augmentation\n        \"\"\"\n        super().__init__()\n        self.data_dir = data_dir\n        self.image_size = image_size\n        self.batch_size = batch_size\n        self.num_workers = num_workers\n        self.data_aug = data_aug\n        self.transforms = self._get_transforms()\n        \n        # Log configuration\n        print(f\"Initializing NatureDataModule:\")\n        print(f\"- Data directory: {self.data_dir}\")\n        print(f\"- Image size: {self.image_size}\")\n        print(f\"- Batch size: {self.batch_size}\")\n        print(f\"- Data augmentation: {self.data_aug}\")\n    \n    def _get_transforms(self):\n        \"\"\"Create transforms for data preprocessing and augmentation\"\"\"\n        base = [\n            transforms.Resize((self.image_size, self.image_size)),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], \n                                std=[0.229, 0.224, 0.225])\n        ]\n        \n        if self.data_aug:\n            augmentations = [\n                transforms.RandomHorizontalFlip(),\n                transforms.ColorJitter(0.1, 0.1, 0.1),\n                transforms.RandomRotation(15)\n            ]\n            # Log the augmentations being used\n            print(\"Using data augmentation:\")\n            print(\" - RandomHorizontalFlip\")\n            print(\" - ColorJitter(0.1, 0.1, 0.1)\")\n            print(\" - RandomRotation(15)\")\n            return transforms.Compose(augmentations + base)\n        else:\n            return transforms.Compose(base)\n    \n    def setup(self, stage=None):\n        \"\"\"Set up the dataset with stratified train/validation split\"\"\"\n        print(\"Setting up dataset...\")\n        full_dataset = ImageFolder(os.path.join(self.data_dir, 'train'), \n                                 transform=self.transforms)\n        \n        # Log class names\n        self.classes = full_dataset.classes\n        print(f\"Classes: {self.classes}\")\n        \n        # Stratified split\n        class_indices = {}\n        for idx, (_, label) in enumerate(full_dataset):\n            if label not in class_indices:\n                class_indices[label] = []\n            class_indices[label].append(idx)\n        \n        train_indices = []\n        val_indices = []\n        \n        # Ensure equal class representation in the validation set\n        for label, indices in class_indices.items():\n            n_val = int(len(indices) * 0.2)  # 20% for validation\n            np.random.shuffle(indices)\n            val_indices.extend(indices[:n_val])\n            train_indices.extend(indices[n_val:])\n            print(f\"Class {label} ({full_dataset.classes[label]}): {len(indices)-n_val} train, {n_val} validation\")\n        \n        self.train_dataset = Subset(full_dataset, train_indices)\n        self.val_dataset = Subset(full_dataset, val_indices)\n        self.test_dataset = ImageFolder(os.path.join(self.data_dir, 'val'),\n                                      transform=self.transforms)\n        \n        print(f\"Total training samples: {len(self.train_dataset)}\")\n        print(f\"Total validation samples: {len(self.val_dataset)}\")\n        print(f\"Total test samples: {len(self.test_dataset)}\")\n\n    def train_dataloader(self):\n        return DataLoader(self.train_dataset, batch_size=self.batch_size,\n                        shuffle=True, num_workers=self.num_workers,\n                        persistent_workers=True if self.num_workers > 0 else False)\n    \n    def val_dataloader(self):\n        return DataLoader(self.val_dataset, batch_size=self.batch_size,\n                        num_workers=self.num_workers, \n                        persistent_workers=True if self.num_workers > 0 else False)\n    \n    def test_dataloader(self):\n        return DataLoader(self.test_dataset, batch_size=self.batch_size,\n                        num_workers=self.num_workers)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T19:12:46.664542Z","iopub.execute_input":"2025-04-18T19:12:46.665609Z","iopub.status.idle":"2025-04-18T19:12:46.677926Z","shell.execute_reply.started":"2025-04-18T19:12:46.665574Z","shell.execute_reply":"2025-04-18T19:12:46.677110Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Hyperparameter Tuning with Weights & Biases","metadata":{}},{"cell_type":"code","source":"\ndef visualize_model(model, dm):\n    \"\"\"Create visualizations for model analysis and log to W&B\"\"\"\n    # Get a batch of test data\n    test_loader = dm.test_dataloader()\n    batch = next(iter(test_loader))\n    images, labels = batch\n    \n    # Get predictions\n    model.eval()\n    with torch.no_grad():\n        logits = model(images)\n        preds = torch.argmax(logits, dim=1)\n    \n    # Log sample predictions\n    fig, axes = plt.subplots(3, 3, figsize=(10, 10))\n    for i, ax in enumerate(axes.flatten()):\n        if i < len(images):\n            # Convert tensor to numpy image\n            img = images[i].permute(1, 2, 0).cpu().numpy()\n            # Denormalize the image\n            mean = np.array([0.485, 0.456, 0.406])\n            std = np.array([0.229, 0.224, 0.225])\n            img = std * img + mean\n            img = np.clip(img, 0, 1)\n            \n            ax.imshow(img)\n            true_class = dm.classes[labels[i]]\n            pred_class = dm.classes[preds[i]]\n            color = 'green' if preds[i] == labels[i] else 'red'\n            ax.set_title(f\"True: {true_class}\\nPred: {pred_class}\", color=color)\n            ax.axis('off')\n    \n    plt.tight_layout()\n    wandb.log({\"prediction_samples\": wandb.Image(fig)})\n    plt.close(fig)\n    \n    # Visualize first layer filters\n    if hasattr(model.features[0], 'weight'):\n        filters = model.features[0].weight.detach().cpu()\n        fig, axes = plt.subplots(4, 8, figsize=(12, 6))\n        for i, ax in enumerate(axes.flatten()):\n            if i < filters.shape[0]:\n                # Take mean across input channels\n                ax.imshow(filters[i].mean(0), cmap='viridis')\n                ax.axis('off')\n        plt.tight_layout()\n        wandb.log({\"first_layer_filters\": wandb.Image(fig)})\n        plt.close(fig)\n    \n    # Log confusion matrix\n    model.eval()\n    all_preds = []\n    all_labels = []\n    \n    for batch in test_loader:\n        images, labels = batch\n        with torch.no_grad():\n            logits = model(images)\n            preds = torch.argmax(logits, dim=1)\n        all_preds.extend(preds.cpu().numpy())\n        all_labels.extend(labels.cpu().numpy())\n    \n    # Convert to numpy arrays\n    all_preds = np.array(all_preds)\n    all_labels = np.array(all_labels)\n    \n    # Create confusion matrix\n    confusion = wandb.plot.confusion_matrix(\n        y_true=all_labels,\n        preds=all_preds,\n        class_names=dm.classes\n    )\n    wandb.log({\"confusion_matrix\": confusion})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T19:12:49.776174Z","iopub.execute_input":"2025-04-18T19:12:49.776924Z","iopub.status.idle":"2025-04-18T19:12:49.788050Z","shell.execute_reply.started":"2025-04-18T19:12:49.776885Z","shell.execute_reply":"2025-04-18T19:12:49.787222Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# WandB sweep configuration\nimport math\n\nsweep_config = {\n    'method': 'random',\n    'metric': {\n        'name': 'val_acc',\n        'goal': 'maximize'\n    },\n    'parameters': {\n        'base_filters': {\n            'values': [16, 32, 64]\n        },\n        'filter_strategy': {\n            'values': ['double', 'halve', 'alternate', 'same']\n        },\n        'base_kernel': {\n            'values': [3, 5, 7]\n        },\n        'kernel_strategy': {\n            'values': ['same', 'decrease', 'alternate', 'pyramid']\n        },\n        'batch_norm': {\n            'values': [True, False]\n        },\n        'conv_activation': {\n            'values': ['relu', 'gelu', 'silu', 'mish']\n        },\n        'dense_activation': {\n            'values': ['relu', 'gelu', 'silu', 'mish']\n        },\n        'dense_size': {\n            'values': [128, 256, 512]\n        },\n        'learning_rate': {\n            'distribution': 'log_uniform_values',\n            'min': 1e-4,\n            'max': 1e-2\n        },\n        'weight_decay': {\n            'distribution': 'log_uniform_values',\n            'min': 1e-6,\n            'max': 1e-3\n        },\n        'dropout': {\n            'values': [0.0, 0.2, 0.3, 0.4, 0.5]\n        },\n        'batch_size': {\n            'values': [32, 64, 128]\n        },\n        'data_aug': {\n            'values': [True, False]\n        }\n    }\n}\n\n\n# Function to train model with given hyperparameters\ndef train_sweep():\n    \"\"\"Train a model with the specified hyperparameters and log results to W&B\"\"\"\n    # Initialize wandb run\n    with wandb.init() as run:\n        config = wandb.config\n        wandb_logger = WandbLogger(log_model='all')\n        \n        # Log hyperparameters to be used\n        print(f\"Training with hyperparameters:\")\n        for key, value in config.items():\n            print(f\"- {key}: {value}\")\n        \n        # Initialize data module\n        dm = NatureDataModule(\n            image_size=128,\n            batch_size=config.batch_size,\n            data_aug=config.data_aug\n        )\n        \n        # Initialize model from sweep config\n        model = NatureCNN(\n            base_filters=config.base_filters,\n            filter_strategy=config.filter_strategy,\n            base_kernel=config.base_kernel,\n            kernel_strategy=config.kernel_strategy,\n            batch_norm=config.batch_norm,\n            conv_activation=config.conv_activation,\n            dense_size=config.dense_size,\n            dense_activation=config.dense_activation,\n            learning_rate=config.learning_rate,\n            weight_decay=config.weight_decay,\n            dropout=config.dropout,\n        )\n        \n        # Log model architecture\n        wandb.log({\"model_summary\": str(model)})\n        \n        # Set up trainer with early stopping and model checkpointing\n        trainer = L.Trainer(\n            max_epochs=5,\n            logger=wandb_logger,\n            callbacks=[\n                EarlyStopping(monitor='val_acc', mode='max', patience=3),\n                ModelCheckpoint(monitor='val_acc', mode='max', filename='best-{epoch:02d}-{val_acc:.4f}')\n            ],\n            precision='16-mixed',  # Use mixed precision for faster training\n            accelerator='auto',\n            devices=1,\n            log_every_n_steps=1000\n        )\n        \n        # Train model\n        trainer.fit(model, dm)\n        \n        # Test best model\n        best_model_path = trainer.checkpoint_callback.best_model_path\n        print(f\"Best model saved at: {best_model_path}\")\n        \n        # best_model = NatureCNN.load_from_checkpoint(best_model_path)\n        # test_results = trainer.test(best_model, dm)\n        \n        # # Log additional metrics and visualizations\n        # visualize_model(best_model, dm)\n        \n        # return test_results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T19:12:52.196330Z","iopub.execute_input":"2025-04-18T19:12:52.196808Z","iopub.status.idle":"2025-04-18T19:12:52.207749Z","shell.execute_reply.started":"2025-04-18T19:12:52.196786Z","shell.execute_reply":"2025-04-18T19:12:52.207127Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Running the Sweep","metadata":{}},{"cell_type":"code","source":"# # Start the sweep\n# sweep_id = wandb.sweep(sweep_config, project=\"Assignment_CNN-partA\")\n# wandb.agent(sweep_id, train_sweep, count=30) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T19:12:55.771650Z","iopub.execute_input":"2025-04-18T19:12:55.771983Z","iopub.status.idle":"2025-04-18T19:12:55.777063Z","shell.execute_reply.started":"2025-04-18T19:12:55.771954Z","shell.execute_reply":"2025-04-18T19:12:55.776222Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Hyperparameter Analysis and Insights","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\nsweep_id = \"mqi3zdx9\"\n\n# Function to analyze sweep results\ndef analyze_sweep_results():\n    \"\"\"Analyze the results from the hyperparameter sweep and generate insights\"\"\"\n    # Initialize wandb API\n    api = wandb.Api()\n    \n    # Get the sweep runs\n    sweep = api.sweep(f\"da24m005-iit-madras/Assignment_CNN-partA/sweeps/{sweep_id}\")\n    runs = sorted(sweep.runs, key=lambda run: run.summary.get('val_acc', 0), reverse=True)\n    \n    print(f\"Total runs: {len(runs)}\")\n    print(f\"Best validation accuracy: {runs[0].summary.get('val_acc', 0):.4f}\")\n    \n    # Extract configurations and metrics for all runs\n    configs = []\n    metrics = []\n    \n    for run in runs:\n        config = {k: v for k, v in run.config.items() \n                 if not k.startswith('_') and k != 'wandb'}\n        metric = {'val_acc': run.summary.get('val_acc', 0),\n                 'test_acc': run.summary.get('test/acc', 0)}\n        configs.append(config)\n        metrics.append(metric)\n    \n    # Create a DataFrame\n    df = pd.DataFrame([{**c, **m} for c, m in zip(configs, metrics)])\n    \n    # Handle non-numeric columns for correlation\n    numeric_df = df.select_dtypes(include=[np.number])\n    \n    # Calculate correlation with validation accuracy\n    corr = numeric_df.corr()['val_acc'].sort_values(ascending=False)\n    print(\"\\nCorrelation with validation accuracy:\")\n    print(corr)\n    \n    # Analyze effect of filter strategy\n    print(\"\\nEffect of filter strategy:\")\n    filter_strategy_effect = df.groupby('filter_strategy')['val_acc'].agg(['mean', 'max', 'count'])\n    print(filter_strategy_effect.sort_values('max', ascending=False))\n    \n    # Analyze effect of activation function\n    print(\"\\nEffect of activation function:\")\n    activation_effect = df.groupby('conv_activation')['val_acc'].agg(['mean', 'max', 'count'])\n    print(activation_effect.sort_values('max', ascending=False))\n    \n    # Analyze effect of batch normalization\n    print(\"\\nEffect of batch normalization:\")\n    bn_effect = df.groupby('batch_norm')['val_acc'].agg(['mean', 'max', 'count'])\n    print(bn_effect)\n    \n    # Analyze effect of data augmentation\n    print(\"\\nEffect of data augmentation:\")\n    aug_effect = df.groupby('data_aug')['val_acc'].agg(['mean', 'max', 'count'])\n    print(aug_effect)\n    \n    # Generate insights (unchanged)\n    print(\"\\nKey insights from hyperparameter sweep:\")\n    \n    # Insight 1: Filter strategy\n    best_filter = filter_strategy_effect.index[filter_strategy_effect['max'].argmax()]\n    print(f\"1. Filter strategy: '{best_filter}' performed best, suggesting that \"\n          f\"{'increasing filter complexity in deeper layers' if best_filter == 'double' else 'maintaining consistent filters across layers' if best_filter == 'same' else 'using alternating filter patterns' if best_filter == 'alternate' else 'reducing filter complexity in deeper layers'} \"\n          f\"is effective for this dataset.\")\n    \n    # Insight 2: Activation function\n    best_activation = activation_effect.index[activation_effect['max'].argmax()]\n    print(f\"2. Activation function: '{best_activation}' yielded the highest accuracy, \"\n          f\"which may be due to its {'better gradient flow' if best_activation in ['gelu', 'silu', 'mish'] else 'simplicity and efficiency' if best_activation == 'relu' else 'special properties'}.\")\n    \n    # Insight 3: Batch normalization\n    bn_better = bn_effect.loc[True, 'mean'] > bn_effect.loc[False, 'mean']\n    print(f\"3. Batch normalization {'improved' if bn_better else 'did not significantly improve'} model performance, \"\n          f\"suggesting it {'helps normalize feature distributions' if bn_better else 'may not be necessary for this dataset'}.\")\n    \n    # Insight 4: Data augmentation\n    aug_better = aug_effect.loc[True, 'mean'] > aug_effect.loc[False, 'mean']\n    print(f\"4. Data augmentation {'improved' if aug_better else 'did not significantly improve'} generalization, \"\n          f\"indicating that {'increasing dataset diversity helps prevent overfitting' if aug_better else 'the dataset may already contain sufficient variety'}.\")\n    \n    # Return the best configuration\n    best_config = {k: runs[0].config[k] for k in configs[0].keys()}\n    return best_config\n\n\n# The function would be called after the sweep completes\nbest_config = analyze_sweep_results()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T19:13:05.552080Z","iopub.execute_input":"2025-04-18T19:13:05.552411Z","iopub.status.idle":"2025-04-18T19:13:07.422882Z","shell.execute_reply.started":"2025-04-18T19:13:05.552388Z","shell.execute_reply":"2025-04-18T19:13:07.422090Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Evaluation on Test Data","metadata":{}},{"cell_type":"code","source":"\ndef visualize_test_predictions(model, dm):\n    \"\"\"Create a grid of test images with model predictions\"\"\"\n    # Get test dataloader\n    test_loader = dm.test_dataloader()\n    \n    # Get a batch of test images\n    all_images = []\n    all_labels = []\n    all_preds = []\n    \n    # Get 30 random samples for visualization\n    for images, labels in test_loader:\n        with torch.no_grad():\n            logits = model(images)\n            preds = torch.argmax(logits, dim=1)\n        \n        all_images.extend(images.cpu())\n        all_labels.extend(labels.cpu())\n        all_preds.extend(preds.cpu())\n        \n        if len(all_images) >= 30:\n            break\n    \n    # Convert to numpy arrays\n    all_images = [img.permute(1, 2, 0).numpy() for img in all_images[:30]]\n    all_labels = [label.item() for label in all_labels[:30]]\n    all_preds = [pred.item() for pred in all_preds[:30]]\n    \n    # Denormalize images\n    mean = np.array([0.485, 0.456, 0.406])\n    std = np.array([0.229, 0.224, 0.225])\n    all_images = [np.clip(std * img + mean, 0, 1) for img in all_images]\n    \n    # Create a grid of images\n    fig, axes = plt.subplots(10, 3, figsize=(12, 30))\n    \n    for i, (img, label, pred) in enumerate(zip(all_images, all_labels, all_preds)):\n        row = i % 10\n        col = i // 10\n        \n        ax = axes[row, col]\n        ax.imshow(img)\n        \n        true_class = dm.classes[label]\n        pred_class = dm.classes[pred]\n        \n        # Green for correct, red for incorrect\n        color = 'green' if label == pred else 'red'\n        \n        ax.set_title(f\"True: {true_class}\\nPred: {pred_class}\", color=color)\n        ax.axis('off')\n    \n    plt.tight_layout()\n    wandb.log({\"test_predictions_grid\": wandb.Image(fig)})\n    plt.close(fig)\n\ndef visualize_filters(model):\n    \"\"\"Visualize filters in the first convolutional layer\"\"\"\n    # Get the first convolutional layer\n    first_conv = model.features[0]\n    \n    # Get the weights\n    weights = first_conv.weight.detach().cpu()\n    \n    # Create a grid of filter visualizations\n    fig, axes = plt.subplots(8, 8, figsize=(12, 12))\n    \n    for i, ax in enumerate(axes.flatten()):\n        if i < weights.shape[0]:\n            # Normalize the filter for visualization\n            filter_img = weights[i].mean(0)  # Average across input channels\n            filter_min, filter_max = filter_img.min(), filter_img.max()\n            filter_img = (filter_img - filter_min) / (filter_max - filter_min + 1e-8)\n            \n            ax.imshow(filter_img, cmap='viridis')\n            ax.axis('off')\n        else:\n            ax.axis('off')\n    \n    plt.tight_layout()\n    wandb.log({\"first_layer_filters\": wandb.Image(fig)})\n    plt.close(fig)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T19:13:13.962075Z","iopub.execute_input":"2025-04-18T19:13:13.962372Z","iopub.status.idle":"2025-04-18T19:13:13.974369Z","shell.execute_reply.started":"2025-04-18T19:13:13.962352Z","shell.execute_reply":"2025-04-18T19:13:13.973699Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def evaluate_best_model():\n    \"\"\"Evaluate the best model from the sweep on the test set\"\"\"\n    # Initialize wandb\n    wandb.init(project=\"Assignment2_CNN-partA\", name=\"best_model_evaluation\")\n\n    wandb_logger = WandbLogger(log_model='all')\n    \n    # Retrieve the best model configuration from the sweep\n    api = wandb.Api()\n    sweep = api.sweep(f\"da24m005-iit-madras/Assignment_CNN-partA/{sweep_id}\")\n    best_run = sorted(sweep.runs, key=lambda run: run.summary.get('val_acc', 0), reverse=True)[0]\n    \n    # Log the best configuration\n    print(\"Best model configuration:\")\n    config = {k: v for k, v in best_run.config.items() if not k.startswith('_') and k != 'wandb'}\n    for k, v in config.items():\n        print(f\"- {k}: {v}\")\n    \n    # Initialize data module\n    dm = NatureDataModule(\n        image_size=128,\n        batch_size=config['batch_size'],\n        data_aug=False  # No augmentation for evaluation\n    )\n    dm.setup()\n    \n    # Initialize model with best configuration\n    model = NatureCNN(\n        base_filters=best_config['base_filters'],\n        filter_strategy=best_config['filter_strategy'],\n        base_kernel=best_config['base_kernel'],\n        kernel_strategy=best_config['kernel_strategy'],\n        batch_norm=best_config['batch_norm'],\n        conv_activation=best_config['conv_activation'],\n        dense_activation=best_config['dense_activation'],\n        dense_size=best_config['dense_size'],\n        learning_rate=best_config['learning_rate'],\n        weight_decay=best_config['weight_decay'],\n        dropout=best_config['dropout']\n    )\n    \n    # Set up trainer\n    trainer = L.Trainer(\n            max_epochs=25,\n            min_epochs=17,\n            logger=wandb_logger,\n            callbacks=[\n                EarlyStopping(monitor='val_acc', mode='max', patience=3),\n                ModelCheckpoint(monitor='val_acc', mode='max', filename='best-{epoch:02d}-{val_acc:.4f}')\n            ],\n            precision='16-mixed',  # Use mixed precision for faster training\n            accelerator='auto',\n            devices=1,\n            log_every_n_steps=1000\n        )\n    \n    trainer.fit(model, dm)\n\n        # Test the model\n    trainer.test(model, dm)\n    \n    # Create and log visualization of predictions\n    visualize_test_predictions(model, dm)\n    \n    # Visualize filters (optional)\n    visualize_filters(model)\n    \n    wandb.finish()\n    \n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T20:31:37.214912Z","iopub.execute_input":"2025-04-18T20:31:37.215282Z","iopub.status.idle":"2025-04-18T20:31:37.224507Z","shell.execute_reply.started":"2025-04-18T20:31:37.215262Z","shell.execute_reply":"2025-04-18T20:31:37.223676Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Call the evaluation function","metadata":{}},{"cell_type":"code","source":"model = evaluate_best_model()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T20:31:40.944446Z","iopub.execute_input":"2025-04-18T20:31:40.944732Z","iopub.status.idle":"2025-04-18T20:44:03.807742Z","shell.execute_reply.started":"2025-04-18T20:31:40.944711Z","shell.execute_reply":"2025-04-18T20:44:03.807105Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}