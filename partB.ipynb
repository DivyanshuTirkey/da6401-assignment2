{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!curl https://storage.googleapis.com/wandb_datasets/nature_12K.zip --output nature_12K.zip\n!unzip nature_12K.zip > /dev/null 2>&1\n!rm nature_12K.zip","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KBJfZadiNRcK","outputId":"0c92ac63-6339-4957-c15c-75c38bea78b6","trusted":true,"execution":{"iopub.status.busy":"2025-04-18T14:23:06.685010Z","iopub.execute_input":"2025-04-18T14:23:06.685276Z","iopub.status.idle":"2025-04-18T14:25:31.944187Z","shell.execute_reply.started":"2025-04-18T14:23:06.685248Z","shell.execute_reply":"2025-04-18T14:25:31.942559Z"}},"outputs":[{"name":"stdout","text":"  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100 3639M  100 3639M    0     0  39.6M      0  0:01:31  0:01:31 --:--:-- 38.5M      0  0:01:34  0:00:39  0:00:55 40.1M 0     0  39.4M      0  0:01:32  0:01:13  0:00:19 39.6M\n/bin/bash: line 1: rm nature_12K.zip: command not found\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# WandB – Install the W&B library\n%pip install wandb -q","metadata":{"id":"I49TpZL9R679","trusted":true,"execution":{"iopub.status.busy":"2025-04-18T14:25:31.948042Z","iopub.execute_input":"2025-04-18T14:25:31.948416Z","iopub.status.idle":"2025-04-18T14:25:37.762454Z","shell.execute_reply.started":"2025-04-18T14:25:31.948382Z","shell.execute_reply":"2025-04-18T14:25:37.761303Z"}},"outputs":[{"name":"stdout","text":"Note: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# !wandb login","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R5g20FzkTJ10","outputId":"0157b33c-d919-44dd-8965-08ccda382b8b","trusted":true,"execution":{"iopub.status.busy":"2025-04-18T14:25:44.587567Z","iopub.execute_input":"2025-04-18T14:25:44.588312Z","iopub.status.idle":"2025-04-18T14:25:44.593171Z","shell.execute_reply.started":"2025-04-18T14:25:44.588268Z","shell.execute_reply":"2025-04-18T14:25:44.592002Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import wandb\nwandb.login(key='130161b8988911058327a18dbbdfb663c58411b2')","metadata":{"id":"l8dr0KZQR7kd","trusted":true,"execution":{"iopub.status.busy":"2025-04-18T14:25:44.906107Z","iopub.execute_input":"2025-04-18T14:25:44.906871Z","iopub.status.idle":"2025-04-18T14:25:54.213779Z","shell.execute_reply.started":"2025-04-18T14:25:44.906839Z","shell.execute_reply":"2025-04-18T14:25:54.213034Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mda24m005\u001b[0m (\u001b[33mda24m005-iit-madras\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"import wandb","metadata":{"id":"FGncFZyETbyd"},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"### Question 1","metadata":{"id":"tRQ9SqmNP9lc"}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, random_split\nfrom torchvision import datasets, transforms, models\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n\n# Set up data transformations to match ImageNet dimensions and normalization\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),  # Resize to match ImageNet dimensions\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                         std=[0.229, 0.224, 0.225])  # ImageNet normalization\n])\n\n# Load the dataset\ntrain_dataset = datasets.ImageFolder('/kaggle/working/inaturalist_12K/train',\n                                    transform=transform)\ntest_dataset = datasets.ImageFolder('/kaggle/working/inaturalist_12K/val',\n                                   transform=transform)\n\n# Create data loaders\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n\n# Load a pre-trained model (ResNet50)\nmodel = models.resnet50(pretrained=True)\n\n# Modify the final fully connected layer to match our 10 classes\nnum_features = model.fc.in_features\nmodel.fc = nn.Linear(num_features, 10)  # 10 classes for iNaturalist\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O0sbTtNnNhsK","outputId":"132388d8-8d27-46dc-a44a-a170c5f8ac0e"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n","100%|██████████| 97.8M/97.8M [00:00<00:00, 113MB/s]\n"]}],"execution_count":6},{"cell_type":"markdown","source":"### Question 2","metadata":{"id":"6rj01HZwQAcK"}},{"cell_type":"code","source":"def freeze_all_except_last(model):\n    \"\"\"Freeze all layers except the final classifier (feature extraction)\"\"\"\n    for param in model.parameters():\n        param.requires_grad = False\n\n    # Unfreeze the final layer\n    for param in model.fc.parameters():\n        param.requires_grad = True\n\n    return model\n\ndef freeze_first_k_layers(model, k=7):\n    \"\"\"Freeze first k layer groups (partial fine-tuning)\"\"\"\n    # Get all children\n    children = list(model.children())\n\n    # Freeze first k layer groups\n    for i in range(k):\n        for param in children[i].parameters():\n            param.requires_grad = False\n\n    return model\n\ndef progressive_unfreezing(model, current_epoch, unfreeze_epoch=5):\n    \"\"\"Progressively unfreeze layers as training progresses\"\"\"\n    if current_epoch == 0:\n        # Start with all layers frozen except the last\n        for param in model.parameters():\n            param.requires_grad = False\n        for param in model.fc.parameters():\n            param.requires_grad = True\n\n    elif current_epoch == unfreeze_epoch:\n        # Unfreeze the last convolutional block\n        for param in model.layer4.parameters():\n            param.requires_grad = True\n\n    return model","metadata":{"id":"QhDoSJopORtE"},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"### Question 3","metadata":{"id":"3vV-Ddd3QC1_"}},{"cell_type":"code","source":"def finetune_model(freeze_strategy=\"feature_extraction\"):\n    \"\"\"Fine-tune the pre-trained model using the specified freezing strategy\"\"\"\n    # Initialize wandb\n    wandb.init(project=\"Assignment2_CNN_partB\", name=f\"resnet50-{freeze_strategy}\")\n\n    # Set device\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    print(f\"Using device: {device}\")\n\n    # Load pre-trained model\n    model = models.resnet50(pretrained=True)\n    num_features = model.fc.in_features\n    model.fc = nn.Linear(num_features, 10)\n\n    # Apply freezing strategy\n    if freeze_strategy == \"feature_extraction\":\n        model = freeze_all_except_last(model)\n        print(\"Using feature extraction: all layers frozen except the last\")\n    elif freeze_strategy == \"partial_finetuning\":\n        model = freeze_first_k_layers(model, k=7)\n        print(\"Using partial fine-tuning: first 7 layer groups frozen\")\n    elif freeze_strategy == \"progressive_unfreezing\":\n        model = progressive_unfreezing(model, current_epoch=0)\n        print(\"Using progressive unfreezing: starting with all layers frozen except the last\")\n\n    model = model.to(device)\n\n    # Count trainable parameters\n    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n    total_params = sum(p.numel() for p in model.parameters())\n    print(f\"Trainable parameters: {trainable_params:,} ({trainable_params/total_params:.2%} of total)\")\n\n    # Set up optimizer and loss function\n    # Use a smaller learning rate for fine-tuning\n    optimizer = optim.Adam([p for p in model.parameters() if p.requires_grad], lr=0.0001)\n    criterion = nn.CrossEntropyLoss()\n\n    # Training loop\n    num_epochs = 25\n    best_accuracy = 0.0\n\n    for epoch in range(num_epochs):\n        # For progressive unfreezing, update which layers are frozen\n        if freeze_strategy == \"progressive_unfreezing\":\n            model = progressive_unfreezing(model, current_epoch=epoch)\n            # Update optimizer to include newly unfrozen parameters\n            if epoch == 5:  # Unfreeze epoch\n                optimizer = optim.Adam([p for p in model.parameters() if p.requires_grad], lr=0.00005)\n                print(\"Unfreezing layer4, adjusting learning rate\")\n\n        # Training phase\n        model.train()\n        running_loss = 0.0\n        correct = 0\n        total = 0\n\n        for images, labels in train_loader:\n            images, labels = images.to(device), labels.to(device)\n\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            running_loss += loss.item()\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n        train_accuracy = correct / total\n        train_loss = running_loss / len(train_loader)\n\n        # Validation phase\n        model.eval()\n        val_loss = 0.0\n        correct = 0\n        total = 0\n\n        with torch.no_grad():\n            for images, labels in test_loader:\n                images, labels = images.to(device), labels.to(device)\n                outputs = model(images)\n                loss = criterion(outputs, labels)\n\n                val_loss += loss.item()\n                _, predicted = torch.max(outputs.data, 1)\n                total += labels.size(0)\n                correct += (predicted == labels).sum().item()\n\n        val_accuracy = correct / total\n        val_loss = val_loss / len(test_loader)\n\n        # Log metrics\n        wandb.log({\n            \"epoch\": epoch,\n            \"train_loss\": train_loss,\n            \"train_accuracy\": train_accuracy,\n            \"val_loss\": val_loss,\n            \"val_accuracy\": val_accuracy,\n            \"trainable_parameters\": trainable_params\n        })\n\n        print(f\"Epoch {epoch+1}/{num_epochs}, \"\n              f\"Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.2f}, \"\n              f\"Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.2f}\")\n\n        # Save best model\n        if val_accuracy > best_accuracy:\n            best_accuracy = val_accuracy\n            torch.save(model.state_dict(), \"best_finetuned_model.pth\")\n            print(f\"New best model saved with accuracy: {best_accuracy:.2f}\")\n\n    # Final test evaluation\n    model.load_state_dict(torch.load(\"best_finetuned_model.pth\"))\n    model.eval()\n    correct = 0\n    total = 0\n\n    with torch.no_grad():\n        for images, labels in test_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    final_accuracy = correct / total\n    print(f\"Final Test Accuracy: {final_accuracy:.2f}\")\n    wandb.log({\"final_test_accuracy\": final_accuracy})\n\n    # Create a visualization of test predictions\n    visualize_predictions(model, test_loader, device, train_dataset)\n\n    wandb.finish()\n    return model, final_accuracy\n\ndef visualize_predictions(model, test_loader, device, train_dataset):  # Add train_dataset as argument\n    \"\"\"Create a visualization of test predictions\"\"\"\n    model.eval()\n    images, labels = next(iter(test_loader))\n    images, labels = images.to(device), labels.to(device)\n\n    outputs = model(images)\n    _, preds = torch.max(outputs, 1)\n\n    class_names = train_dataset.classes  # Get class names\n\n    # Plot a grid of images with predictions\n    fig, axes = plt.subplots(4, 8, figsize=(15, 8))\n    axes = axes.flatten()\n\n    for i in range(min(32, len(images))):\n        img = images[i].cpu().permute(1, 2, 0).numpy()\n        # Denormalize\n        img = img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n        img = np.clip(img, 0, 1)\n\n        axes[i].imshow(img)\n        pred_class_name = class_names[preds[i].item()]  # Get predicted class name\n        true_class_name = class_names[labels[i].item()]  # Get true class name\n        color = 'green' if preds[i] == labels[i] else 'red'\n        axes[i].set_title(f\"Pred: {pred_class_name}\", color=color)  # Display class name\n        axes[i].axis('off')\n\n    plt.tight_layout()\n    wandb.log({\"test_predictions\": wandb.Image(fig)})\n    plt.close()\n\n# Run the fine-tuning with feature extraction strategy (freezing all layers except the last)\nmodel, accuracy = finetune_model(freeze_strategy=\"feature_extraction\")\n","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"j5bc-hXEOR-Q","outputId":"f60ea1f1-c456-4d97-fd2f-88e417250dc2"},"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mda24m005\u001b[0m (\u001b[33mda24m005-iit-madras\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.19.9"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20250418_122949-p47kumb6</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/da24m005-iit-madras/Assignment_CNN_partB/runs/p47kumb6' target=\"_blank\">resnet50-feature_extraction</a></strong> to <a href='https://wandb.ai/da24m005-iit-madras/Assignment_CNN_partB' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/da24m005-iit-madras/Assignment_CNN_partB' target=\"_blank\">https://wandb.ai/da24m005-iit-madras/Assignment_CNN_partB</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/da24m005-iit-madras/Assignment_CNN_partB/runs/p47kumb6' target=\"_blank\">https://wandb.ai/da24m005-iit-madras/Assignment_CNN_partB/runs/p47kumb6</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Using device: cuda\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["Using feature extraction: all layers frozen except the last\n","Trainable parameters: 20,490 (0.09% of total)\n","Epoch 1/25, Train Loss: 1.7203, Train Acc: 0.53%, Val Loss: 1.2960, Val Acc: 0.67%\n","New best model saved with accuracy: 0.67%\n","Epoch 2/25, Train Loss: 1.1799, Train Acc: 0.68%, Val Loss: 1.0195, Val Acc: 0.71%\n","New best model saved with accuracy: 0.71%\n","Epoch 3/25, Train Loss: 1.0097, Train Acc: 0.71%, Val Loss: 0.9191, Val Acc: 0.73%\n","New best model saved with accuracy: 0.73%\n","Epoch 4/25, Train Loss: 0.9232, Train Acc: 0.73%, Val Loss: 0.8466, Val Acc: 0.74%\n","New best model saved with accuracy: 0.74%\n","Epoch 5/25, Train Loss: 0.8773, Train Acc: 0.73%, Val Loss: 0.8138, Val Acc: 0.75%\n","New best model saved with accuracy: 0.75%\n","Epoch 6/25, Train Loss: 0.8424, Train Acc: 0.74%, Val Loss: 0.7890, Val Acc: 0.75%\n","New best model saved with accuracy: 0.75%\n","Epoch 7/25, Train Loss: 0.8173, Train Acc: 0.75%, Val Loss: 0.7663, Val Acc: 0.76%\n","New best model saved with accuracy: 0.76%\n","Epoch 8/25, Train Loss: 0.8005, Train Acc: 0.74%, Val Loss: 0.7529, Val Acc: 0.76%\n","New best model saved with accuracy: 0.76%\n","Epoch 9/25, Train Loss: 0.7867, Train Acc: 0.75%, Val Loss: 0.7559, Val Acc: 0.76%\n","Epoch 10/25, Train Loss: 0.7699, Train Acc: 0.75%, Val Loss: 0.7171, Val Acc: 0.77%\n","New best model saved with accuracy: 0.77%\n","Epoch 11/25, Train Loss: 0.7549, Train Acc: 0.76%, Val Loss: 0.7132, Val Acc: 0.77%\n","Epoch 12/25, Train Loss: 0.7520, Train Acc: 0.76%, Val Loss: 0.7177, Val Acc: 0.77%\n","Epoch 13/25, Train Loss: 0.7530, Train Acc: 0.76%, Val Loss: 0.7252, Val Acc: 0.77%\n","Epoch 14/25, Train Loss: 0.7367, Train Acc: 0.76%, Val Loss: 0.7140, Val Acc: 0.77%\n","Epoch 15/25, Train Loss: 0.7308, Train Acc: 0.76%, Val Loss: 0.7202, Val Acc: 0.77%\n","Epoch 16/25, Train Loss: 0.7260, Train Acc: 0.76%, Val Loss: 0.7159, Val Acc: 0.77%\n","New best model saved with accuracy: 0.77%\n","Epoch 17/25, Train Loss: 0.7228, Train Acc: 0.77%, Val Loss: 0.6957, Val Acc: 0.78%\n","New best model saved with accuracy: 0.78%\n","Epoch 18/25, Train Loss: 0.7111, Train Acc: 0.77%, Val Loss: 0.7087, Val Acc: 0.77%\n","Epoch 19/25, Train Loss: 0.7099, Train Acc: 0.77%, Val Loss: 0.6892, Val Acc: 0.78%\n","New best model saved with accuracy: 0.78%\n","Epoch 20/25, Train Loss: 0.7072, Train Acc: 0.77%, Val Loss: 0.6992, Val Acc: 0.77%\n","Epoch 21/25, Train Loss: 0.7018, Train Acc: 0.78%, Val Loss: 0.6975, Val Acc: 0.76%\n","Epoch 22/25, Train Loss: 0.6963, Train Acc: 0.77%, Val Loss: 0.6973, Val Acc: 0.78%\n","Epoch 23/25, Train Loss: 0.6995, Train Acc: 0.77%, Val Loss: 0.7023, Val Acc: 0.77%\n","Epoch 24/25, Train Loss: 0.6910, Train Acc: 0.77%, Val Loss: 0.6950, Val Acc: 0.78%\n","Epoch 25/25, Train Loss: 0.6796, Train Acc: 0.78%, Val Loss: 0.6929, Val Acc: 0.77%\n","Final Test Accuracy: 0.78%\n"]},{"output_type":"error","ename":"TypeError","evalue":"visualize_predictions() missing 1 required positional argument: 'train_dataset'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-6f84d386c51f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;31m# Run the fine-tuning with feature extraction strategy (freezing all layers except the last)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinetune_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfreeze_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"feature_extraction\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-8-6f84d386c51f>\u001b[0m in \u001b[0;36mfinetune_model\u001b[0;34m(freeze_strategy)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;31m# Create a visualization of test predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m     \u001b[0mvisualize_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: visualize_predictions() missing 1 required positional argument: 'train_dataset'"]}],"execution_count":8}]}